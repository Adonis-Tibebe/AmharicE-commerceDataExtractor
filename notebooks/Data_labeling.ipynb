{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1509ea",
   "metadata": {},
   "source": [
    "## Data Labeling notebook\n",
    "It will contain:\n",
    "- Converting the Message column of the processed data to a random 100 non duplicate jason format data and save it in 'data/' directoy\n",
    "- we will then load the saved json file into Label Studios \n",
    "- after labelign using label studios we will export the CoNLL format data \n",
    "- we will allign BIO labels with transformer token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce2e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad61d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "loaded data successfully‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "print(\"loading data...\")\n",
    "data = pd.read_csv('../data/processed/cleaned_normalized_data.csv')\n",
    "print(\"loaded data successfully‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592aaaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokenized_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7399</td>\n",
       "      <td>GROOMING SET ·à∂·àµ·âµ ·â†·ä†·äï·ãµ ·ã®·ã´·ãò ·ã®·çÄ·åâ·à≠ ·àõ·àΩ·äï ·ä•·äì ·àº·â®·à≠ ·ã®·àö·à∞·à´...</td>\n",
       "      <td>2025-06-20 15:25:41+00:00</td>\n",
       "      <td>../data/raw/photo\\@Shageronlinestore_7399.jpg</td>\n",
       "      <td>['·ãõ·àù_·àû·àç']</td>\n",
       "      <td>['GROOMING', 'SET', '·à∂·àµ·âµ', '·â†·ä†·äï·ãµ', '·ã®·ã´·ãò', '·ã®·çÄ·åâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7395</td>\n",
       "      <td>GROOMING SET ·à∂·àµ·âµ ·â†·ä†·äï·ãµ ·ã®·ã´·ãò ·ã®·çÄ·åâ·à≠ ·àõ·àΩ·äï ·ä•·äì ·àº·â®·à≠ ·ã®·àö·à∞·à´...</td>\n",
       "      <td>2025-06-20 15:25:40+00:00</td>\n",
       "      <td>../data/raw/photo\\@Shageronlinestore_7395.jpg</td>\n",
       "      <td>['·ãõ·àù_·àû·àç']</td>\n",
       "      <td>['GROOMING', 'SET', '·à∂·àµ·âµ', '·â†·ä†·äï·ãµ', '·ã®·ã´·ãò', '·ã®·çÄ·åâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7393</td>\n",
       "      <td>1L Water Bottle High Quality 1L water time sca...</td>\n",
       "      <td>2025-06-20 11:47:53+00:00</td>\n",
       "      <td>../data/raw/photo\\@Shageronlinestore_7393.jpg</td>\n",
       "      <td>['·ãõ·àù_·àû·àç']</td>\n",
       "      <td>['1L', 'Water', 'Bottle', 'High', 'Quality', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7391</td>\n",
       "      <td>Sonifer Steam Iron ·ã®·àç·â•·àµ ·àò·â∂·ä®·àª High Quality Cera...</td>\n",
       "      <td>2025-06-20 09:03:23+00:00</td>\n",
       "      <td>../data/raw/photo\\@Shageronlinestore_7391.jpg</td>\n",
       "      <td>['·ãõ·àù_·àû·àç']</td>\n",
       "      <td>['Sonifer', 'Steam', 'Iron', '·ã®·àç·â•·àµ', '·àò·â∂·ä®·àª', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7390</td>\n",
       "      <td>Sayona multifunctional juicer and extractor Be...</td>\n",
       "      <td>2025-06-20 06:48:11+00:00</td>\n",
       "      <td>../data/raw/photo\\@Shageronlinestore_7390.jpg</td>\n",
       "      <td>['·ãõ·àù_·àû·àç']</td>\n",
       "      <td>['Sayona', 'multifunctional', 'juicer', 'and',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Channel Title    Channel Username    ID  \\\n",
       "0  Sheger online-store  @Shageronlinestore  7399   \n",
       "1  Sheger online-store  @Shageronlinestore  7395   \n",
       "2  Sheger online-store  @Shageronlinestore  7393   \n",
       "3  Sheger online-store  @Shageronlinestore  7391   \n",
       "4  Sheger online-store  @Shageronlinestore  7390   \n",
       "\n",
       "                                             Message  \\\n",
       "0  GROOMING SET ·à∂·àµ·âµ ·â†·ä†·äï·ãµ ·ã®·ã´·ãò ·ã®·çÄ·åâ·à≠ ·àõ·àΩ·äï ·ä•·äì ·àº·â®·à≠ ·ã®·àö·à∞·à´...   \n",
       "1  GROOMING SET ·à∂·àµ·âµ ·â†·ä†·äï·ãµ ·ã®·ã´·ãò ·ã®·çÄ·åâ·à≠ ·àõ·àΩ·äï ·ä•·äì ·àº·â®·à≠ ·ã®·àö·à∞·à´...   \n",
       "2  1L Water Bottle High Quality 1L water time sca...   \n",
       "3  Sonifer Steam Iron ·ã®·àç·â•·àµ ·àò·â∂·ä®·àª High Quality Cera...   \n",
       "4  Sayona multifunctional juicer and extractor Be...   \n",
       "\n",
       "                        Date                                     Media Path  \\\n",
       "0  2025-06-20 15:25:41+00:00  ../data/raw/photo\\@Shageronlinestore_7399.jpg   \n",
       "1  2025-06-20 15:25:40+00:00  ../data/raw/photo\\@Shageronlinestore_7395.jpg   \n",
       "2  2025-06-20 11:47:53+00:00  ../data/raw/photo\\@Shageronlinestore_7393.jpg   \n",
       "3  2025-06-20 09:03:23+00:00  ../data/raw/photo\\@Shageronlinestore_7391.jpg   \n",
       "4  2025-06-20 06:48:11+00:00  ../data/raw/photo\\@Shageronlinestore_7390.jpg   \n",
       "\n",
       "    hashtags                                      tokenized_msg  \n",
       "0  ['·ãõ·àù_·àû·àç']  ['GROOMING', 'SET', '·à∂·àµ·âµ', '·â†·ä†·äï·ãµ', '·ã®·ã´·ãò', '·ã®·çÄ·åâ...  \n",
       "1  ['·ãõ·àù_·àû·àç']  ['GROOMING', 'SET', '·à∂·àµ·âµ', '·â†·ä†·äï·ãµ', '·ã®·ã´·ãò', '·ã®·çÄ·åâ...  \n",
       "2  ['·ãõ·àù_·àû·àç']  ['1L', 'Water', 'Bottle', 'High', 'Quality', '...  \n",
       "3  ['·ãõ·àù_·àû·àç']  ['Sonifer', 'Steam', 'Iron', '·ã®·àç·â•·àµ', '·àò·â∂·ä®·àª', '...  \n",
       "4  ['·ãõ·àù_·àû·àç']  ['Sayona', 'multifunctional', 'juicer', 'and',...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first few rows of the data\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386dd6b",
   "metadata": {},
   "source": [
    "## we will save a random 100 sample of text data into a jasonl file \n",
    "- jsonl format is necessary for annotation using label studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to 'telegram_ecommerce_data_sample.jsonl' successfully‚úÖ\n"
     ]
    }
   ],
   "source": [
    "(data[[\"Message\"]] # Select the 'Message' column not as a series but as a dataframe\n",
    " .sample(n=100, random_state=42) # Sample 100 messages randomly\n",
    " .reset_index(drop=True) # Reset index for the sampled data\n",
    " .rename(columns={\"Message\": \"text\"})\n",
    " .to_json(\"../data/processed/telegram_ecommerce_data_sample.jsonl\", orient=\"records\", lines=True, force_ascii=False)) # Save the sampled messages to a JSONL file\n",
    "print(\"Sampled data saved to 'telegram_ecommerce_data_sample.jsonl' successfully‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e46caa",
   "metadata": {},
   "source": [
    "We will convert the Jsonl file into a regular json array file of Json extention to load data using label-studios GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac34c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSONL to JSON array and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"../data/processed/telegram_ecommerce_data_sample.jsonl\", \"r\", encoding=\"utf-8\") as infile:\n",
    "    for line in infile:\n",
    "        if line.strip():  # make sure not to process empty lines\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "with open(\"../data/processed/telegram_ecommerce_data_sample.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(data, outfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Converted JSONL to JSON array and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6b1d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONLL data successfully exported from label-studios in CONLL 2003 format\n",
      "-DOCSTART- -X- O\n",
      "SUN -X- _ B-PRODUCT\n",
      "5 -X- _ I-PRODUCT\n",
      "Nail -X- _ I-PRODUCT\n",
      "Dryer -X- _ I-PRODUCT\n",
      ": -X- _ O\n",
      "Infrared -X- _ B-PROD_COMPONENT\n",
      "intelligent -X- _ I-PROD_COMPONENT\n",
      "induction -X- _ I-PROD_COMPONENT\n",
      "( -X- _ O\n",
      "30 -X- _ O\n",
      "S -X- _ O\n",
      "60 -X- _ O\n",
      "S -X- _ O\n",
      "90 -X- _ O\n",
      "S -X- _ O\n",
      "timing -X- _ O\n",
      ") -X- _ O\n",
      "LCD -X- _ B-PROD_COMPONENT\n",
      "display -X- _ I-PROD_COMPONENT\n",
      "Bottom -X- _ I-PROD_COMPONENT\n",
      "cooling -X- _ I-PROD_COMPONENT\n",
      "hole -X- _ I-PROD_COMPONENT\n",
      "·ãã·åã·ç¶ -X- _ B-PRICE\n",
      "2600 -X- _ I-PRICE\n",
      "·â•·à≠ -X- _ I-PRICE\n",
      "·ãç·àµ·äï -X- _ O\n",
      "·çç·à¨ -X- _ O\n",
      "·äê·ãç -X- _ O\n",
      "·ã´·àà·ãç -X- _ O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CONLL data successfully exported from label-studios in CONLL 2003 format\")\n",
    "with open(\"../data/processed/telegram_labeled_data.conll\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "print(\"\".join(lines[:30]))  # Show first few lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0aca4d",
   "metadata": {},
   "source": [
    "## CONLL Format Labled Data Structure\n",
    "we have labeled each data using **6 tags**:\n",
    "- PRODUCT -> the product sold\n",
    "- LOC -> the location entity \n",
    "- PRICE -> selling price of product (when available)\n",
    "- CONTACT -> contact info of the seller\n",
    "- PROD_COMPONENT -> specs of products and ingredients for products that has such specifications\n",
    "- DELIVERY_FEE -> delivery fee of sellers that offer delivery services\n",
    "\n",
    "NOTE: labeling was done manually for about 100 randomly selected messages from the cleaned_normalized_data using Lable-Studios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021290b",
   "metadata": {},
   "source": [
    "# üìí Data Labeling Notebook Summary\n",
    "\n",
    "This notebook documents the workflow for preparing, sampling, and labeling Amharic e-commerce Telegram messages for Named Entity Recognition (NER) tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Loading Preprocessed Data**\n",
    "- Loads cleaned and normalized Telegram message data from `../data/processed/cleaned_normalized_data.csv`.\n",
    "- Data is inspected to verify structure and content.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Sampling for Annotation**\n",
    "- Randomly selects 100 unique messages from the dataset.\n",
    "- Renames the `Message` column to `text` for annotation compatibility.\n",
    "- Saves the sample in JSONL format (`telegram_ecommerce_data_sample.jsonl`) for use with Label Studio.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Format Conversion for Label Studio**\n",
    "- Converts the JSONL sample to a standard JSON array (`telegram_ecommerce_data_sample.json`) for easier loading into Label Studio's GUI.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Labeling Workflow**\n",
    "- The sampled data is imported into Label Studio for manual annotation.\n",
    "- **NOTE:** Labeling was done manually for about 100 randomly selected messages from the cleaned and normalized data using Label Studio.\n",
    "- After annotation, the labeled data is exported in CoNLL 2003 format (`telegram_labeled_data.conll`).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **NER Tagging Schema**\n",
    "The following six entity tags are used for labeling:\n",
    "- **PRODUCT**: The product being sold.\n",
    "- **LOC**: Location entities.\n",
    "- **PRICE**: Selling price (when available).\n",
    "- **CONTACT**: Seller's contact information.\n",
    "- **PROD_COMPONENT**: Product specifications or ingredients.\n",
    "- **DELIVERY_FEE**: Delivery fee information for sellers offering delivery.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Post-Labeling**\n",
    "- The notebook demonstrates how to read and preview the exported CoNLL data.\n",
    "- Next steps: Aligning BIO labels with transformer tokens for model training.\n",
    "\n",
    "---\n",
    "\n",
    "**Result:**  \n",
    "A reproducible workflow for sampling, annotating, and exporting labeled Amharic e-commerce Telegram messages, ready for downstream NER modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
